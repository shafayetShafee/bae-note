# Solutions to Chapter 06 Exercises

> DISCLAIMER: please note that these are not the official solutions, just some stuff from my head with a very limited knowledge. So proceed with caution and verify. Also please do me a favor by letting me know of the mistakes and better approaches to these exercises' solution.

## Practice: Grid approximation


```{r}
#| message: false
# Load packages
library(tidyverse)
library(janitor)
library(rstan)
library(bayesplot)
```


::: {#exr-6.5}
# Beta-Binomial grid approximation

Consider the Beta-Binomial model for $\pi$ with $Y | \pi ∼ Bin (n , \pi)$ and $π ∼ Beta (3, 8)$. Suppose that in $n = 10$ independent trials, you observe $Y = 2$ successes.

a. Utilize grid approximation with grid values $π ∈ \{0 , 0.25 , 0.5 , 0.75 , 1 \}$ to approximate the posterior model of $π$ . 
b. Repeat part a using a grid of 201 equally spaced values between 0 and 1.

:::


::: {#sol-6.5-a}

# a

```{r}
#| message: false
#| warning: false
tibble(
  # Define a grid of pi values
  pi_grid = c(0, 0.25, 0.5, 0.75, 1),
  
  # Evaluate the prior and llk at each value of grid
  prior = dbeta(pi_grid, 3, 8),
  likelihood = dbinom(2, size = 10, prob = pi_grid),
  unnormalized = prior * likelihood,
  
  # Calculate the posterior
  posterior = unnormalized / sum(unnormalized)
) %>% 
  # Sample from posterior
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  
  # Plot the histogram of posterior simulation 
  ggplot(aes(x = pi_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  # overlay the theoretical posterior for comparison
  stat_function(fun = dbeta, args = list(5, 16)) +
  xlim(c(0, 1))
```
:::

::: {#sol-6.5-b}

# b

```{r}
#| message: false
#| warning: false
tibble(
  # Define a grid of pi values
  pi_grid = seq(from = 0, to = 1, length = 201),
  
  # Evaluate the prior and llk at each value of grid
  prior = dbeta(pi_grid, 3, 8),
  likelihood = dbinom(2, size = 10, prob = pi_grid),
  unnormalized = prior * likelihood,
  
  # Calculate the posterior
  posterior = unnormalized / sum(unnormalized)
) %>% 
  # Sample from posterior
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  
  # Plot the histogram of posterior simulation 
  ggplot(aes(x = pi_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  # overlay the theoretical posterior for comparison
  stat_function(fun = dbeta, args = list(5, 16)) +
  xlim(c(0, 1))
```
:::


::: {#exr-6.6}
# Gamma-Poisson grid approximation

Consider the Gamma-Poisson model for $\lambda$ with $Y_i|\lambda \sim Pois(\lambda)$ and $\lambda ~ Gamma(20, 5)$ Suppose you observe $n = 3$ independent data points $(Y_1, Y_2, Y_3) = (0, 1, 0)$.

 a. Utilize grid approximation with grid values $\lambda ∈ \{0, 1, 2, \dots, 8\}$ to approximate the posterior model of $\lambda$. 
 b. Repeat part a using a grid of 201 equally spaced values between 0 and 8.

:::

::: {#sol-6.6}

# a

```{r}
#| message: false
#| warning: false
tibble(
  lambda_grid = 0:8,
  prior = dgamma(lambda_grid, 20, 5),
  llk = dpois(0, lambda_grid) * dpois(1, lambda_grid) * dpois(0, lambda_grid),
  unnormalized = prior * llk,
  posterior = unnormalized / sum(unnormalized)
) %>% 
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  ggplot(aes(x = lambda_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  stat_function(fun = dgamma, args = list(21, 8)) +
  xlim(c(0, 8))
```
:::


::: {#sol-6.6-b}
# b

```{r}
#| message: false
#| warning: false
tibble(
  lambda_grid = seq(from = 0, to = 8, length = 201),
  prior = dgamma(lambda_grid, 20, 5),
  llk = dpois(0, lambda_grid) * dpois(1, lambda_grid) * dpois(0, lambda_grid),
  unnormalized = prior * llk,
  posterior = unnormalized / sum(unnormalized)
) %>% 
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  ggplot(aes(x = lambda_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  stat_function(fun = dgamma, args = list(21, 8)) +
  xlim(c(0, 8))
```

:::


::: {#exr-6.7}

# Normal-Normal grid approximation

Consider the Normal-Normal model for $\mu$ with $Y_i \sim N(\mu, 1.3^2)$ and $\mu \sim N(10, 1.2^2)$. Suppose that on $n = 4$ independent observations, you observe data $(Y_1, Y_2, Y_3, Y_4) = ( 7.1 , 8.9 , 8.4 , 8.6)$. 

a. Utilize grid approximation with grid values $\mu ∈ \{ 5 , 6 , 7 , \dots , 15 \}$ to approximate the posterior model of $\mu$ . 
b. Repeat part a using a grid of 201 equally spaced values between 5 and 15

:::


::: {#sol-6.7}

# a

```{r}
calc_llk <- function(obs, par, pdf_func, ...) {
  llk <- outer(obs, par, pdf_func, ...) |> 
    apply(MARGIN = 2, FUN = prod)
  
  return(llk)
}
```

```{r}
#| message: false
#| warning: false
tibble(
  mu_grid = 5:15,
  prior = dnorm(mu_grid, 10, 1.2),
  llk = calc_llk(c(7.1, 8.9, 8.4, 8.6), mu_grid, dnorm, sd = 1.3),
  unnormalized = prior * llk,
  posterior = unnormalized / sum(unnormalized)
) %>% 
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  ggplot(aes(x = mu_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  stat_function(fun = dnorm, args = list(8.64697, 0.5715)) +
  xlim(c(5, 15))
```
:::

::: {#sol-6.7-b}
# b

```{r}
#| message: false
#| warning: false
tibble(
  mu_grid = seq(5, 15, length = 201),
  prior = dnorm(mu_grid, 10, 1.2),
  llk = calc_llk(c(7.1, 8.9, 8.4, 8.6), mu_grid, dnorm, sd = 1.3),
  unnormalized = prior * llk,
  posterior = unnormalized / sum(unnormalized)
) %>% 
  sample_n(size = 10000, replace = TRUE, weight = posterior) %>% 
  ggplot(aes(x = mu_grid)) +
  geom_histogram(aes(y = after_stat(density))) +
  stat_function(fun = dnorm, args = list(8.64697, 0.5715)) +
  xlim(c(5, 15))
```

:::


## Practice: MCMC

::: {#exr-6.12}
# MCMC with RStan: Steps 1 and 2

Use the given information to (1) define the Bayesian model structure, and (2) simulate the posterior using the correct RStan syntax. You don’t need to run the code, just provide the syntax.

a. $Y|\pi \sim Bin(20, \pi)$ and $\pi \sim Beta(1, 1)$ with $Y = 12$.
b. $Y|\lambda \sim Pois(\lambda)$ and $\lambda \sim Gamma(4, 2)$ with $Y = 3$.
c. $Y|\mu \sim N(\mu, 1^2)$ and $\mu \sim N(0, 10^2)$ with $Y = 12.2$.

:::

::: {#sol-6.12-a}

# a

```{r}
#| eval: false
bb_model <- "
  data {
    int<lower = 0, upper = 20> Y;
  }
  
  parameters {
    real<lower = 0, upper = 1> pi;
  }
  
  model {
    Y ~ binomial(20, pi);
    pi ~ beta(1, 1);
  }
"

bb_sim <- stan(model_code = bb_model, data = list(Y = 12),
               chains = 4, iter = 5000*2, seed = 84735)
```

:::

::: {#sol-6.12-b}

# b

```{r}
#| eval: false
gp_model <- "
  data {
    int<lower = 0> Y;
  }
  
  parameters {
    real<lower = 0> lambda;
  }
  
  model {
    Y ~ poisson(lambda);
    lambda ~ gamma(4, 2);
  }
"

gp_sim <- stan(model_code = gp_model, data = list(Y = 3),
               chains = 4, iter = 5000*2, seed = 84735)
```

:::

::: {#sol-6.12-c}

```{r}
#| eval: false
nn_model <- "
  data {
    real Y;
  }
  
  parameters {
    real mu;
  }
  
  model {
    Y ~ normal(mu, 1);
    mu ~ normal(0, 10);
  }
"

nn_sim <- stan(model_code = nn_model, data = list(Y = 12.2),
               chains = 4, iter = 5000*2, seed = 84735)
```

:::